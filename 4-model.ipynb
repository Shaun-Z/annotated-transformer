{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b024d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336e57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389afb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.53.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c396d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.53.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"hfl/rbt3\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b9d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50812421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7a9b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f71c14",
   "metadata": {},
   "source": [
    "# Call models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c1689c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3297, 3953, 2207, 4638, 2769, 3300, 1920, 1920, 4638, 3457, 2682,\n",
       "          102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '最渺小的我有大大的梦想'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "inputs = tokenizer(sen, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b5398",
   "metadata": {},
   "source": [
    "## Call without model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f087e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\", output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c3be03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1845,  0.1603,  0.0723,  ..., -0.0012,  0.2330, -0.2811],\n",
       "         [-0.1626,  0.0132,  0.1397,  ..., -0.5918,  0.3093, -0.9131],\n",
       "         [-0.8569,  0.2801,  0.0680,  ..., -0.5486,  0.2291, -0.6269],\n",
       "         ...,\n",
       "         [-0.3182,  0.2777,  0.4023,  ..., -0.2696, -0.1960, -0.3751],\n",
       "         [ 0.0401,  0.7028, -0.2772,  ..., -0.3170,  0.3985,  0.1387],\n",
       "         [ 0.1787,  0.1625,  0.0690,  ...,  0.0041,  0.2299, -0.2769]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.5137e-02, -9.9762e-01, -9.9992e-01, -6.5477e-01,  8.7581e-01,\n",
       "         -9.1917e-02,  3.0853e-03,  8.3910e-02,  9.8929e-01,  9.9649e-01,\n",
       "          5.6079e-02, -1.0000e+00,  7.7966e-02,  9.9961e-01, -9.9996e-01,\n",
       "          9.9969e-01,  9.8627e-01,  9.3786e-01, -9.9846e-01, -2.0064e-01,\n",
       "         -9.9332e-01, -8.3254e-01,  2.5813e-01,  9.9090e-01,  9.6877e-01,\n",
       "         -9.9186e-01, -9.9973e-01,  1.6177e-01, -6.7935e-01, -9.9749e-01,\n",
       "         -9.4736e-01, -9.9961e-01,  2.5382e-01, -1.2207e-01,  9.9244e-01,\n",
       "         -8.6369e-01,  1.6169e-01, -9.5505e-01, -9.9204e-01, -9.9078e-01,\n",
       "         -1.1308e-01,  9.7551e-01, -1.8494e-02,  9.9964e-01, -7.9827e-02,\n",
       "         -5.6833e-03,  9.9990e-01,  9.9514e-01, -2.8585e-01, -5.8118e-01,\n",
       "         -3.0516e-01, -3.8747e-01, -9.8402e-01,  9.9862e-01,  1.2297e-01,\n",
       "          1.0257e-01,  9.9949e-01, -9.9999e-01, -9.9853e-01,  9.7358e-01,\n",
       "         -9.9920e-01,  9.9218e-01,  9.9563e-01,  9.8527e-01, -8.0850e-01,\n",
       "          9.9916e-01,  9.8573e-01,  9.5924e-01, -2.9301e-01, -9.9994e-01,\n",
       "          2.8740e-01, -9.5159e-01, -9.9973e-01,  6.3518e-02, -1.4420e-02,\n",
       "         -9.9680e-01,  9.9066e-01, -1.5223e-01,  9.9953e-01,  4.1377e-01,\n",
       "         -9.9894e-01,  2.2407e-01, -5.9782e-04,  4.2995e-02,  9.9758e-01,\n",
       "          9.9998e-01,  4.6207e-02, -9.8549e-01, -2.5112e-01, -9.9150e-01,\n",
       "         -2.3334e-01,  9.9370e-01,  9.9981e-01, -9.9714e-01,  9.9985e-01,\n",
       "         -7.6035e-01, -2.0860e-01,  3.1620e-01, -9.9175e-01,  9.4635e-01,\n",
       "         -1.7120e-01, -2.2353e-01,  9.9998e-01,  9.9246e-01,  4.9258e-01,\n",
       "         -9.9928e-01, -8.8092e-01,  9.9330e-01, -9.9201e-01,  2.3541e-01,\n",
       "          9.9999e-01,  5.7437e-01,  1.0000e+00,  9.9925e-01,  9.9993e-01,\n",
       "         -9.9950e-01, -4.2478e-01,  2.2065e-01, -9.9952e-01,  9.9562e-01,\n",
       "         -9.7358e-01,  4.3350e-01, -3.7451e-01, -3.1284e-01,  1.5538e-01,\n",
       "         -9.9979e-01, -5.7845e-02,  9.1641e-02, -9.9478e-01, -9.9858e-01,\n",
       "         -9.9317e-01, -9.9982e-01,  9.3582e-01,  8.7506e-01,  6.5809e-02,\n",
       "         -4.1854e-01,  2.2370e-01, -1.3522e-01, -9.9996e-01, -9.9907e-01,\n",
       "         -9.9988e-01, -5.3270e-01, -5.8109e-01,  9.9188e-01, -9.9389e-01,\n",
       "          9.9703e-01, -9.9776e-01,  9.9939e-01,  9.8675e-01,  3.8635e-02,\n",
       "         -1.7276e-01, -9.1692e-02, -9.9644e-01,  1.0920e-01, -2.5012e-01,\n",
       "          9.9400e-01,  9.9214e-01,  8.7881e-01, -7.3893e-01,  9.9995e-01,\n",
       "         -9.7665e-01,  9.5494e-01, -4.4581e-03,  9.7821e-01,  9.9999e-01,\n",
       "         -9.9990e-01,  2.3951e-01, -1.0000e+00,  4.2676e-01,  6.0045e-02,\n",
       "          9.9950e-01,  9.9746e-01,  5.0285e-01,  9.9807e-01, -5.6061e-01,\n",
       "         -9.9962e-01, -3.0245e-02, -9.9978e-01,  4.9504e-01,  9.9996e-01,\n",
       "         -5.5983e-02,  6.1469e-01,  9.9998e-01, -5.1247e-01,  8.9243e-01,\n",
       "         -7.2088e-03,  7.4777e-02, -9.9746e-01,  1.6292e-01,  3.3591e-01,\n",
       "          9.6114e-01, -9.4259e-01,  2.8309e-01,  8.4003e-01, -7.4662e-02,\n",
       "         -6.5943e-02, -9.9293e-01, -9.9489e-01,  9.9915e-01,  9.9535e-01,\n",
       "          4.1764e-01, -1.7277e-01,  9.9997e-01, -6.0215e-02,  9.9936e-01,\n",
       "          3.1038e-01,  8.0858e-01, -3.2489e-01,  9.9437e-01,  3.4561e-01,\n",
       "          2.5851e-01, -4.9349e-02,  9.9981e-01, -4.2243e-01, -9.9953e-01,\n",
       "          4.4230e-02, -4.4869e-01,  3.8923e-01, -9.8353e-01,  3.1640e-01,\n",
       "         -2.6191e-01,  9.9975e-01, -5.1067e-03, -9.7224e-01,  9.8578e-01,\n",
       "         -9.9763e-01,  3.1299e-01, -9.9997e-01, -9.9661e-01,  9.9941e-01,\n",
       "          1.0356e-01, -1.0000e+00,  7.6188e-01,  9.9999e-01, -8.9078e-01,\n",
       "          9.9780e-01, -2.7312e-01, -9.9941e-01,  1.1577e-02, -1.8799e-01,\n",
       "         -9.9999e-01, -9.9593e-01, -9.9999e-01, -7.4889e-01,  1.4981e-02,\n",
       "          9.7181e-01, -9.9998e-01,  1.2761e-01, -9.9985e-01,  9.9758e-01,\n",
       "          9.9989e-01,  3.0320e-02, -4.0394e-01,  9.9996e-01,  3.1750e-01,\n",
       "          3.2602e-02,  2.8241e-01,  1.1145e-01,  1.9816e-01,  9.9396e-01,\n",
       "          4.5762e-01,  9.9892e-01, -9.9910e-01,  2.9534e-01, -1.9268e-01,\n",
       "         -9.9987e-01, -3.7705e-01,  7.3720e-01,  5.3302e-02,  7.1664e-02,\n",
       "         -9.1417e-02,  1.9780e-01,  9.7304e-01,  9.9276e-01,  9.9999e-01,\n",
       "          9.3028e-01,  9.9998e-01,  9.9989e-01, -1.2101e-02, -9.7712e-01,\n",
       "         -8.0729e-01, -7.7534e-02, -9.9983e-01, -8.9538e-01, -9.9479e-01,\n",
       "          8.5442e-01,  1.7925e-01,  1.0000e+00, -9.9994e-01,  9.9998e-01,\n",
       "         -8.5266e-01,  4.3546e-02, -1.2564e-01,  2.6778e-01, -4.7418e-01,\n",
       "          7.8581e-03,  9.9526e-01, -1.6950e-02,  8.7517e-01,  9.8347e-01,\n",
       "          1.4975e-02,  2.3129e-02,  3.6672e-01,  9.7721e-02,  9.8850e-01,\n",
       "         -9.3500e-01,  9.7719e-01, -6.6012e-02,  9.9780e-01, -1.8016e-01,\n",
       "         -9.9998e-01,  9.9940e-01, -9.9853e-01, -3.5978e-01, -9.9858e-01,\n",
       "         -9.3890e-01,  9.1515e-02, -9.9808e-01,  9.6012e-01,  9.9527e-01,\n",
       "          1.4489e-01, -2.9005e-01, -9.9993e-01, -8.5482e-01,  9.7388e-01,\n",
       "          9.9953e-01, -9.9989e-01,  9.9545e-01,  9.5451e-01, -8.0867e-01,\n",
       "          2.5381e-01,  7.0822e-01, -9.9703e-01,  9.9928e-01, -9.9994e-01,\n",
       "          7.7446e-02,  9.7611e-01,  3.0124e-02, -9.9957e-01, -8.2726e-01,\n",
       "         -1.2149e-01,  6.8653e-01,  2.2020e-01,  9.9933e-01, -3.6908e-01,\n",
       "          3.7184e-02, -9.9969e-01, -9.2484e-01, -4.3761e-01,  8.8773e-02,\n",
       "          9.9549e-01, -9.9995e-01,  7.0810e-01,  9.9934e-01, -9.9633e-01,\n",
       "         -5.2846e-01, -1.4412e-02,  1.1680e-01,  1.6145e-01, -9.8578e-01,\n",
       "         -9.9986e-01, -9.9813e-01,  9.9970e-01,  2.4414e-02, -5.9899e-01,\n",
       "          9.9434e-01,  9.9897e-01,  9.9945e-01, -9.8974e-01,  8.6323e-01,\n",
       "          9.9870e-01, -1.7088e-01,  2.8424e-01, -5.1974e-01, -5.6404e-01,\n",
       "         -8.5882e-01, -9.5686e-01,  2.3447e-01,  6.3180e-01,  2.8783e-01,\n",
       "         -9.9280e-01,  9.9965e-01,  9.9956e-01,  9.9998e-01,  1.0244e-01,\n",
       "         -8.7040e-01,  7.3792e-01, -9.3518e-01, -9.9713e-01,  3.3128e-02,\n",
       "          9.9929e-01, -9.9861e-01,  9.8558e-02,  3.0126e-01, -9.9637e-01,\n",
       "          9.9553e-01, -9.7896e-01,  1.8507e-01, -9.9999e-01, -9.9872e-01,\n",
       "         -9.9999e-01,  9.9993e-01,  1.5038e-01, -3.0114e-01, -9.9801e-01,\n",
       "          9.9999e-01,  9.9724e-01, -8.9035e-01, -2.3286e-01,  9.9974e-01,\n",
       "         -5.6898e-01, -5.0303e-02, -9.9997e-01, -9.9862e-01,  9.8656e-01,\n",
       "         -9.3379e-02,  9.9923e-01, -5.0131e-01, -9.8781e-01,  5.5143e-01,\n",
       "          9.6397e-01,  2.0543e-01, -9.7057e-01, -9.8250e-01,  2.4535e-01,\n",
       "          3.4331e-01,  2.2451e-02,  6.6900e-02, -5.8422e-02,  9.9927e-01,\n",
       "          7.9066e-02, -9.4917e-02, -2.0697e-01,  9.9989e-01,  4.2123e-01,\n",
       "         -9.9295e-01, -8.2622e-01, -6.1389e-02, -9.6821e-01, -9.9888e-01,\n",
       "         -9.9935e-01,  2.5803e-04,  1.2826e-02,  2.0434e-01, -9.6642e-01,\n",
       "         -9.9975e-01, -9.9875e-01,  1.5516e-02, -9.8460e-01, -9.4007e-01,\n",
       "         -2.5668e-02, -9.9865e-01, -9.8746e-01,  9.9677e-01, -9.9888e-01,\n",
       "         -1.5641e-01,  9.6446e-01,  9.8566e-01, -9.9973e-01, -1.2551e-01,\n",
       "          9.8844e-01, -9.7958e-01,  3.4953e-01, -9.3746e-01, -2.1652e-01,\n",
       "         -8.0505e-01, -9.9992e-01,  1.4712e-01,  9.9944e-01,  9.9919e-01,\n",
       "          9.8876e-01,  9.1693e-01, -8.4220e-01,  9.3558e-01,  9.9504e-01,\n",
       "          9.9995e-01, -2.1044e-02, -7.7581e-02, -9.9995e-01,  3.2687e-01,\n",
       "          8.9072e-01,  1.6856e-01,  8.1171e-01, -9.9888e-01,  5.8708e-02,\n",
       "         -6.4728e-01,  1.6048e-01,  1.0000e+00,  9.6406e-01, -3.6899e-01,\n",
       "         -9.9999e-01,  2.0266e-02, -3.0839e-01, -6.7344e-03, -9.7522e-01,\n",
       "          3.3610e-01,  9.9994e-01, -9.8803e-01, -2.3622e-02, -9.9663e-01,\n",
       "         -9.9808e-01,  9.9983e-01, -9.9990e-01,  9.9993e-01,  8.9340e-01,\n",
       "         -9.0856e-01, -6.0071e-02, -6.0800e-01, -2.1589e-01, -7.9701e-03,\n",
       "         -4.8217e-02,  1.1053e-02, -1.1474e-01, -9.9996e-01, -1.2354e-01,\n",
       "          9.7455e-01, -2.7015e-01, -8.3157e-01, -9.9561e-01,  1.0547e-01,\n",
       "          9.9242e-01, -9.9876e-01, -9.9935e-01, -1.0836e-01, -1.9114e-01,\n",
       "          4.7748e-01, -5.8280e-01,  8.7923e-02,  4.5378e-02, -9.0423e-01,\n",
       "         -7.0009e-02,  9.5176e-01, -2.6144e-01,  7.3938e-01, -9.8224e-01,\n",
       "         -9.8289e-01, -3.7194e-01,  9.9959e-01,  9.9769e-01, -9.9947e-01,\n",
       "         -9.9966e-01,  9.1771e-02, -3.2408e-02,  1.5717e-01,  9.9775e-01,\n",
       "         -1.6840e-01, -9.9385e-01,  1.0998e-01,  1.3178e-01, -1.5376e-01,\n",
       "         -8.0804e-01,  9.9997e-01, -9.7685e-01,  9.9999e-01, -9.9998e-01,\n",
       "         -8.0108e-01,  8.1432e-03,  9.9986e-01, -9.9979e-01, -4.0156e-01,\n",
       "          9.9544e-01, -9.9994e-01, -1.4354e-01, -8.3052e-01,  5.0401e-01,\n",
       "         -1.2210e-01, -6.6726e-02,  8.0165e-01, -9.9633e-01,  1.9673e-01,\n",
       "         -9.9813e-01,  4.3336e-01,  9.5212e-01, -9.9946e-01, -8.1580e-01,\n",
       "         -9.9998e-01, -1.0358e-01, -1.0133e-01, -9.9967e-01,  9.7612e-01,\n",
       "          9.9992e-01, -1.2783e-01,  8.7157e-01, -9.9911e-01,  9.6285e-02,\n",
       "         -3.7479e-01, -9.9796e-01, -7.1013e-02, -9.9948e-01,  4.8526e-01,\n",
       "         -9.9711e-01,  9.5444e-01, -9.9986e-01,  9.7827e-01,  9.5866e-01,\n",
       "         -2.3634e-01, -2.2693e-01, -1.0611e-01, -5.8004e-01, -9.9979e-01,\n",
       "          1.9916e-01, -9.9691e-01, -9.9866e-01,  1.4630e-01,  9.9866e-01,\n",
       "          9.4622e-01,  1.4770e-01,  9.8760e-01, -9.8611e-01,  1.3447e-01,\n",
       "          2.5317e-01,  4.4220e-01,  1.0000e+00, -9.9958e-01, -9.9547e-01,\n",
       "          9.8404e-01, -9.9945e-01, -8.5921e-01,  1.0000e+00, -7.2971e-01,\n",
       "          9.9956e-01,  8.5415e-02, -9.9410e-01,  2.2302e-01,  2.1518e-01,\n",
       "          9.9362e-01, -1.7700e-01, -8.8982e-02,  9.9812e-01, -1.2876e-01,\n",
       "          1.1598e-01, -8.6191e-01,  9.7577e-01,  6.6929e-03,  5.5179e-02,\n",
       "          9.6819e-01, -9.7743e-01, -9.9731e-01, -9.9812e-01,  1.5404e-01,\n",
       "         -2.9430e-01, -2.1035e-01, -7.3394e-02,  7.2852e-01,  9.9982e-01,\n",
       "         -9.9946e-01,  9.8905e-01, -1.0000e+00, -9.9975e-01,  4.3120e-02,\n",
       "          3.2045e-01,  9.9718e-01,  6.4193e-02, -6.9327e-01, -7.2079e-02,\n",
       "         -9.8281e-01,  9.4026e-01, -9.9736e-01,  9.7062e-01,  4.5951e-02,\n",
       "          3.6749e-02,  9.9943e-01,  9.9805e-01,  4.2772e-02, -9.8595e-01,\n",
       "         -9.4589e-01,  4.1927e-02, -9.9720e-01,  9.9881e-01,  1.2848e-01,\n",
       "          1.5515e-01,  9.0139e-02, -9.1611e-02, -9.9569e-01, -9.8334e-01,\n",
       "          3.5045e-03,  9.7667e-01, -9.9953e-01,  9.4761e-01, -9.8389e-01,\n",
       "          9.8784e-01,  9.9480e-01,  1.0000e+00, -9.7263e-03,  9.5505e-01,\n",
       "         -9.9938e-01, -9.8153e-01,  9.9666e-01,  9.0733e-01,  9.9998e-01,\n",
       "          8.8952e-01,  9.3868e-01,  3.9191e-02, -9.9993e-01,  9.8164e-01,\n",
       "         -2.3273e-01, -7.7642e-02, -7.5531e-02, -9.0458e-01, -9.9988e-01,\n",
       "          9.9993e-01, -9.9996e-01, -9.9989e-01, -9.4151e-01, -9.9931e-01,\n",
       "          9.9389e-01,  9.1487e-01,  9.9890e-01,  6.7895e-01, -9.9914e-01,\n",
       "         -9.9060e-01, -3.7214e-02, -9.7915e-01, -9.8394e-01, -2.2418e-02,\n",
       "         -9.9999e-01, -6.0462e-02, -3.4726e-02, -9.7334e-01,  5.5519e-01,\n",
       "         -9.2410e-01,  7.4468e-01,  9.9126e-01, -3.1138e-01,  8.8147e-01,\n",
       "         -9.4446e-01, -9.9590e-01,  8.0043e-02, -9.9999e-01,  9.7632e-01,\n",
       "          9.9971e-01,  1.2639e-01,  2.8125e-01, -6.4731e-01, -1.3817e-02,\n",
       "         -9.9996e-01, -1.0000e+00,  9.6731e-01,  9.9989e-01,  4.3434e-01,\n",
       "         -9.9720e-01,  1.8185e-01, -9.9967e-01,  1.5734e-01,  8.8528e-01,\n",
       "          9.9411e-01, -9.9949e-01,  9.9112e-01, -8.8209e-01,  1.3938e-02,\n",
       "          9.9189e-01, -1.0000e+00,  5.3850e-01, -9.9871e-01,  9.9941e-01,\n",
       "         -1.0000e+00,  9.9765e-01, -5.0052e-01, -6.0636e-02,  1.1459e-01,\n",
       "          8.3965e-01, -9.9995e-01, -2.1598e-01,  9.5862e-01,  9.4297e-01,\n",
       "         -2.1690e-01,  9.9714e-01,  1.0037e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[4.7288e-01, 1.0186e-03, 7.0093e-04,  ..., 2.2776e-04,\n",
       "           1.6561e-04, 5.2195e-01],\n",
       "          [4.3638e-03, 2.5035e-01, 2.8193e-02,  ..., 1.3796e-01,\n",
       "           1.3916e-01, 4.0677e-03],\n",
       "          [1.9618e-02, 3.0751e-02, 4.3187e-02,  ..., 7.9549e-02,\n",
       "           8.3890e-02, 6.9625e-03],\n",
       "          ...,\n",
       "          [2.9872e-02, 3.9502e-02, 7.1421e-02,  ..., 2.7812e-01,\n",
       "           1.3002e-01, 6.3906e-03],\n",
       "          [3.0202e-02, 1.0688e-01, 3.9472e-02,  ..., 1.7636e-01,\n",
       "           1.2379e-01, 1.2315e-02],\n",
       "          [4.3969e-01, 2.0401e-03, 8.2232e-04,  ..., 4.2301e-04,\n",
       "           2.9548e-04, 5.5378e-01]],\n",
       "\n",
       "         [[9.9049e-01, 1.7043e-04, 4.6340e-05,  ..., 7.1014e-05,\n",
       "           4.2860e-05, 3.0067e-03],\n",
       "          [9.9142e-01, 2.8482e-03, 2.3157e-03,  ..., 9.9998e-06,\n",
       "           1.4983e-09, 1.2882e-03],\n",
       "          [3.7311e-02, 1.8280e-03, 5.0099e-04,  ..., 3.5409e-07,\n",
       "           2.2554e-05, 7.7136e-07],\n",
       "          ...,\n",
       "          [2.3574e-02, 6.8866e-06, 6.1640e-08,  ..., 2.3398e-05,\n",
       "           9.4223e-01, 4.2026e-04],\n",
       "          [1.0767e-02, 2.8903e-10, 6.3975e-06,  ..., 9.7457e-01,\n",
       "           1.5369e-04, 1.4442e-02],\n",
       "          [9.7413e-01, 2.2735e-04, 1.3760e-07,  ..., 1.3832e-04,\n",
       "           9.0498e-03, 4.6937e-03]],\n",
       "\n",
       "         [[1.8217e-01, 5.6630e-02, 7.8697e-02,  ..., 3.9950e-02,\n",
       "           5.1009e-02, 2.3424e-01],\n",
       "          [4.9926e-01, 2.8066e-01, 2.6397e-02,  ..., 7.6410e-03,\n",
       "           5.2658e-03, 1.2878e-01],\n",
       "          [4.4712e-01, 9.7988e-02, 9.4963e-02,  ..., 1.2487e-02,\n",
       "           1.0399e-02, 2.0783e-01],\n",
       "          ...,\n",
       "          [1.4934e-01, 5.4482e-02, 3.5200e-02,  ..., 1.2154e-01,\n",
       "           1.9545e-02, 4.1372e-02],\n",
       "          [1.4881e-01, 2.8938e-02, 3.3975e-02,  ..., 6.4894e-02,\n",
       "           7.0338e-02, 5.0249e-02],\n",
       "          [4.2857e-02, 2.6633e-02, 3.0351e-02,  ..., 1.1524e-01,\n",
       "           4.9838e-02, 1.4211e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[6.7169e-01, 4.1369e-02, 4.9464e-03,  ..., 2.4945e-02,\n",
       "           2.5135e-02, 7.4265e-02],\n",
       "          [2.7079e-01, 5.8909e-03, 1.1616e-02,  ..., 6.2663e-02,\n",
       "           1.1577e-01, 3.2583e-01],\n",
       "          [4.7839e-01, 1.4396e-02, 6.1569e-02,  ..., 1.4255e-01,\n",
       "           9.5712e-02, 5.6006e-02],\n",
       "          ...,\n",
       "          [5.2826e-01, 5.0243e-02, 5.7187e-02,  ..., 2.2048e-01,\n",
       "           2.3081e-02, 1.6586e-02],\n",
       "          [3.1799e-01, 5.6777e-02, 1.0164e-01,  ..., 7.0797e-02,\n",
       "           2.1609e-01, 7.9970e-02],\n",
       "          [3.9741e-01, 4.0318e-02, 3.5496e-02,  ..., 1.5468e-02,\n",
       "           1.0268e-02, 1.4279e-01]],\n",
       "\n",
       "         [[9.7527e-01, 2.3552e-03, 5.9668e-03,  ..., 1.1920e-03,\n",
       "           1.7990e-03, 3.9784e-03],\n",
       "          [7.5997e-03, 2.2948e-02, 6.1035e-01,  ..., 2.9348e-03,\n",
       "           1.8403e-03, 6.1834e-03],\n",
       "          [1.6548e-02, 1.9130e-02, 4.1211e-02,  ..., 1.6748e-03,\n",
       "           6.4489e-04, 8.5198e-03],\n",
       "          ...,\n",
       "          [6.1232e-03, 5.7317e-04, 1.4284e-03,  ..., 2.6964e-02,\n",
       "           3.4743e-01, 5.9654e-01],\n",
       "          [1.2584e-03, 2.2923e-05, 1.8403e-04,  ..., 1.7234e-03,\n",
       "           5.3727e-03, 9.8437e-01],\n",
       "          [9.9454e-01, 6.0303e-06, 2.4952e-05,  ..., 1.1931e-04,\n",
       "           3.5865e-04, 4.7028e-03]],\n",
       "\n",
       "         [[4.2027e-01, 4.1451e-02, 3.2255e-02,  ..., 1.5277e-02,\n",
       "           1.3353e-02, 3.1007e-01],\n",
       "          [7.5182e-01, 7.0975e-02, 2.3976e-02,  ..., 2.9551e-02,\n",
       "           1.8028e-03, 1.0205e-02],\n",
       "          [1.1700e-01, 7.3406e-01, 1.8126e-02,  ..., 1.2712e-02,\n",
       "           1.3159e-02, 5.5627e-03],\n",
       "          ...,\n",
       "          [1.3484e-01, 4.4387e-03, 8.2395e-03,  ..., 1.7597e-02,\n",
       "           8.3566e-03, 2.2783e-02],\n",
       "          [3.8191e-02, 4.6281e-04, 1.2384e-04,  ..., 8.7615e-01,\n",
       "           2.5483e-02, 7.9407e-03],\n",
       "          [1.0090e-01, 8.5796e-03, 1.0337e-03,  ..., 3.7993e-02,\n",
       "           1.4292e-01, 6.8070e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.4901e-01, 1.1793e-02, 1.1104e-02,  ..., 1.1341e-02,\n",
       "           1.2582e-02, 4.3158e-01],\n",
       "          [4.8834e-01, 4.9734e-03, 1.1814e-02,  ..., 5.9625e-03,\n",
       "           6.7796e-05, 4.6739e-01],\n",
       "          [3.2078e-01, 3.6705e-01, 2.0318e-03,  ..., 3.1275e-05,\n",
       "           5.4126e-04, 2.8963e-01],\n",
       "          ...,\n",
       "          [3.2688e-01, 2.0174e-04, 3.0745e-04,  ..., 5.2296e-03,\n",
       "           3.9220e-03, 3.1659e-01],\n",
       "          [7.4042e-02, 6.4581e-06, 1.2671e-05,  ..., 8.4837e-01,\n",
       "           6.4275e-05, 7.5012e-02],\n",
       "          [4.5054e-01, 1.1218e-02, 1.0576e-02,  ..., 1.0850e-02,\n",
       "           1.3253e-02, 4.3300e-01]],\n",
       "\n",
       "         [[4.6079e-01, 1.0799e-02, 1.1615e-02,  ..., 7.7414e-03,\n",
       "           6.1897e-03, 4.4702e-01],\n",
       "          [1.6583e-01, 4.5592e-02, 3.6818e-02,  ..., 2.3293e-02,\n",
       "           4.5082e-02, 1.6863e-01],\n",
       "          [3.3904e-01, 6.7757e-03, 1.3193e-02,  ..., 4.7217e-02,\n",
       "           3.7293e-02, 3.4123e-01],\n",
       "          ...,\n",
       "          [3.9869e-01, 1.1977e-02, 1.0120e-02,  ..., 2.5222e-02,\n",
       "           5.5486e-02, 3.9821e-01],\n",
       "          [2.8026e-01, 2.0535e-02, 4.5696e-02,  ..., 4.9345e-02,\n",
       "           1.1676e-01, 2.7838e-01],\n",
       "          [4.6279e-01, 1.0040e-02, 1.0786e-02,  ..., 7.4791e-03,\n",
       "           5.9080e-03, 4.4929e-01]],\n",
       "\n",
       "         [[4.9471e-01, 3.4199e-03, 8.9620e-03,  ..., 5.1316e-03,\n",
       "           2.7199e-03, 4.4692e-01],\n",
       "          [4.4361e-01, 1.0059e-01, 1.0348e-03,  ..., 9.8886e-04,\n",
       "           1.5199e-03, 4.2571e-01],\n",
       "          [4.8825e-01, 1.6741e-03, 2.6624e-02,  ..., 4.2993e-03,\n",
       "           2.8202e-03, 4.6215e-01],\n",
       "          ...,\n",
       "          [3.2045e-01, 2.0320e-03, 1.2998e-02,  ..., 3.3490e-01,\n",
       "           2.5329e-02, 2.9476e-01],\n",
       "          [3.7560e-01, 4.3423e-04, 1.7764e-02,  ..., 2.2223e-01,\n",
       "           2.9528e-02, 3.4987e-01],\n",
       "          [4.9453e-01, 3.4623e-03, 8.9571e-03,  ..., 5.4924e-03,\n",
       "           2.8591e-03, 4.4625e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.4344e-01, 2.2019e-02, 1.5493e-02,  ..., 1.1879e-02,\n",
       "           1.8879e-02, 4.2033e-01],\n",
       "          [7.4496e-02, 8.9870e-03, 2.6339e-02,  ..., 2.8645e-02,\n",
       "           1.2829e-02, 7.7531e-02],\n",
       "          [2.7176e-01, 1.1164e-03, 1.5455e-02,  ..., 2.6032e-02,\n",
       "           1.2741e-02, 2.7911e-01],\n",
       "          ...,\n",
       "          [4.0931e-01, 1.7077e-03, 2.7024e-03,  ..., 5.9146e-02,\n",
       "           7.0805e-02, 4.1408e-01],\n",
       "          [4.3469e-01, 2.5487e-02, 2.1239e-02,  ..., 1.8373e-02,\n",
       "           2.0605e-02, 4.2567e-01],\n",
       "          [4.4518e-01, 2.1155e-02, 1.4673e-02,  ..., 1.1540e-02,\n",
       "           1.8567e-02, 4.2241e-01]],\n",
       "\n",
       "         [[4.7776e-01, 4.5713e-03, 4.8056e-03,  ..., 6.6344e-03,\n",
       "           5.1251e-03, 4.4872e-01],\n",
       "          [2.7048e-01, 8.5923e-02, 5.5030e-02,  ..., 3.6280e-02,\n",
       "           2.1435e-02, 2.6765e-01],\n",
       "          [4.6517e-01, 1.5902e-02, 1.6224e-02,  ..., 3.1406e-03,\n",
       "           3.3680e-03, 4.5458e-01],\n",
       "          ...,\n",
       "          [1.8567e-01, 7.7073e-02, 9.5395e-02,  ..., 2.4509e-02,\n",
       "           2.9693e-02, 1.8122e-01],\n",
       "          [1.9369e-01, 8.8924e-02, 7.0236e-02,  ..., 1.9762e-02,\n",
       "           2.3461e-02, 1.9499e-01],\n",
       "          [4.7734e-01, 4.6138e-03, 4.8183e-03,  ..., 6.5515e-03,\n",
       "           5.0443e-03, 4.4878e-01]],\n",
       "\n",
       "         [[4.7432e-01, 3.5470e-03, 2.6062e-02,  ..., 6.1332e-03,\n",
       "           2.3278e-03, 4.5435e-01],\n",
       "          [3.0960e-01, 4.4624e-02, 9.3414e-02,  ..., 3.3195e-02,\n",
       "           2.6841e-02, 3.0001e-01],\n",
       "          [3.7407e-01, 3.4513e-02, 2.8855e-02,  ..., 2.9171e-02,\n",
       "           6.3252e-02, 3.6581e-01],\n",
       "          ...,\n",
       "          [3.2807e-01, 4.1476e-02, 6.7492e-02,  ..., 3.7630e-02,\n",
       "           5.3650e-02, 3.1734e-01],\n",
       "          [3.5886e-01, 2.8796e-02, 7.8483e-02,  ..., 4.6495e-02,\n",
       "           2.2035e-02, 3.5294e-01],\n",
       "          [4.7474e-01, 3.3838e-03, 2.5393e-02,  ..., 6.1750e-03,\n",
       "           2.2922e-03, 4.5498e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.7756e-01, 1.5403e-02, 5.9107e-02,  ..., 1.1186e-02,\n",
       "           3.5646e-02, 3.7186e-01],\n",
       "          [4.6716e-01, 1.8549e-02, 1.1425e-02,  ..., 1.2130e-03,\n",
       "           7.8485e-03, 4.6184e-01],\n",
       "          [4.8272e-01, 1.5021e-02, 1.4922e-02,  ..., 3.3218e-04,\n",
       "           7.1750e-04, 4.7548e-01],\n",
       "          ...,\n",
       "          [3.2561e-01, 2.7407e-02, 6.5780e-02,  ..., 6.7897e-03,\n",
       "           5.5800e-03, 3.1962e-01],\n",
       "          [2.7112e-01, 2.4349e-02, 5.2617e-02,  ..., 1.4981e-02,\n",
       "           1.4040e-02, 2.6618e-01],\n",
       "          [3.7819e-01, 1.5309e-02, 5.8923e-02,  ..., 1.1186e-02,\n",
       "           3.5522e-02, 3.7248e-01]],\n",
       "\n",
       "         [[1.7147e-02, 1.0301e-01, 1.2424e-01,  ..., 4.6998e-02,\n",
       "           1.8595e-01, 1.7042e-02],\n",
       "          [2.7021e-02, 2.7542e-03, 9.1249e-01,  ..., 1.5667e-03,\n",
       "           1.0975e-03, 2.6492e-02],\n",
       "          [3.0747e-01, 1.1490e-02, 3.6383e-02,  ..., 1.2024e-03,\n",
       "           2.3790e-03, 3.0248e-01],\n",
       "          ...,\n",
       "          [2.8702e-01, 5.1580e-04, 4.9020e-03,  ..., 1.7039e-02,\n",
       "           3.2158e-01, 2.8375e-01],\n",
       "          [3.8375e-01, 3.4743e-04, 2.9309e-02,  ..., 1.7655e-01,\n",
       "           1.7292e-02, 3.8168e-01],\n",
       "          [1.7212e-02, 1.0347e-01, 1.2424e-01,  ..., 4.7234e-02,\n",
       "           1.8674e-01, 1.7106e-02]],\n",
       "\n",
       "         [[4.8331e-01, 8.0192e-03, 7.4905e-03,  ..., 5.9849e-04,\n",
       "           3.1297e-03, 4.7837e-01],\n",
       "          [4.1941e-01, 1.6169e-02, 5.0314e-02,  ..., 1.9619e-02,\n",
       "           1.5108e-02, 4.1394e-01],\n",
       "          [4.4618e-01, 2.0154e-03, 6.0998e-02,  ..., 7.4828e-03,\n",
       "           9.6120e-03, 4.4001e-01],\n",
       "          ...,\n",
       "          [4.6675e-01, 1.4783e-03, 1.4760e-02,  ..., 2.0973e-02,\n",
       "           1.4010e-02, 4.5896e-01],\n",
       "          [4.1703e-01, 1.9264e-03, 8.8986e-03,  ..., 3.3243e-02,\n",
       "           7.7678e-02, 4.1058e-01],\n",
       "          [4.8324e-01, 8.0526e-03, 7.5273e-03,  ..., 6.0641e-04,\n",
       "           3.1518e-03, 4.7830e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.7605e-02, 1.4897e-01, 1.9517e-01,  ..., 8.2557e-02,\n",
       "           1.3234e-01, 3.7223e-02],\n",
       "          [1.5491e-01, 2.5536e-02, 1.5990e-01,  ..., 1.0970e-02,\n",
       "           6.7965e-03, 1.5200e-01],\n",
       "          [4.4193e-01, 2.5747e-03, 1.9162e-02,  ..., 1.1076e-02,\n",
       "           5.1654e-03, 4.3603e-01],\n",
       "          ...,\n",
       "          [4.6996e-01, 4.7168e-04, 2.3850e-03,  ..., 1.8285e-02,\n",
       "           2.7615e-02, 4.6633e-01],\n",
       "          [4.9382e-01, 6.6575e-04, 5.8455e-04,  ..., 6.3828e-03,\n",
       "           4.9909e-03, 4.8950e-01],\n",
       "          [3.7975e-02, 1.4884e-01, 1.9506e-01,  ..., 8.2291e-02,\n",
       "           1.3188e-01, 3.7590e-02]],\n",
       "\n",
       "         [[3.1113e-02, 4.6256e-02, 8.8200e-02,  ..., 1.1009e-01,\n",
       "           4.1771e-01, 3.0936e-02],\n",
       "          [4.9421e-01, 7.2562e-03, 4.3358e-03,  ..., 5.1516e-04,\n",
       "           4.9965e-04, 4.8732e-01],\n",
       "          [4.8218e-01, 2.8101e-02, 9.2247e-03,  ..., 6.4776e-04,\n",
       "           2.1302e-04, 4.7247e-01],\n",
       "          ...,\n",
       "          [2.3692e-01, 6.2217e-03, 6.0570e-03,  ..., 1.4907e-02,\n",
       "           1.0000e-02, 2.3256e-01],\n",
       "          [2.0413e-01, 3.2294e-03, 3.7542e-03,  ..., 4.4753e-02,\n",
       "           2.8196e-02, 2.0037e-01],\n",
       "          [3.1151e-02, 4.5787e-02, 8.7559e-02,  ..., 1.1058e-01,\n",
       "           4.1940e-01, 3.0973e-02]],\n",
       "\n",
       "         [[2.0622e-01, 4.3068e-02, 8.4066e-02,  ..., 6.5023e-02,\n",
       "           9.4458e-02, 2.0225e-01],\n",
       "          [1.0439e-01, 6.1733e-03, 6.5168e-01,  ..., 3.8480e-03,\n",
       "           5.8740e-03, 1.0282e-01],\n",
       "          [4.4273e-01, 1.7905e-03, 8.8049e-03,  ..., 8.6360e-04,\n",
       "           7.2287e-04, 4.3793e-01],\n",
       "          ...,\n",
       "          [4.5064e-01, 8.5864e-04, 1.5554e-03,  ..., 1.1307e-02,\n",
       "           4.6693e-02, 4.4948e-01],\n",
       "          [4.9398e-01, 6.4078e-04, 7.5614e-04,  ..., 2.1620e-03,\n",
       "           3.7944e-03, 4.9528e-01],\n",
       "          [2.0714e-01, 4.3121e-02, 8.3398e-02,  ..., 6.4882e-02,\n",
       "           9.3886e-02, 2.0316e-01]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f72fb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d225328",
   "metadata": {},
   "source": [
    "## Call with model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2978138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dbe6688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clz_model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\", num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467d724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2918, -0.6561, -0.0037,  0.4088, -0.4928,  0.5762,  0.1645, -0.2092,\n",
       "         -0.0241,  0.1899]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869b1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
