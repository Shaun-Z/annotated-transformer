{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8c6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformer import EncoderDecoder, Encoder, Decoder, TransformerLayer, Generator, MultiHeadAttention, FeedForward, EmbeddingsWithPositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ce1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab_size, tgt_vocab_size, n_layers=6, d_model=512, n_heads=8, dropout_prob=0.1):\n",
    "\n",
    "    encoder = Encoder(\n",
    "                    layer=TransformerLayer(\n",
    "                        d_model=d_model,\n",
    "                        self_attn=MultiHeadAttention(d_model=d_model, n_heads=n_heads, dropout_prob=dropout_prob), \n",
    "                        feed_forward=FeedForward(d_model=d_model, d_ff=2048, dropout_prob=dropout_prob),\n",
    "                        dropout_prob=dropout_prob\n",
    "                    ),\n",
    "                    n_layers=n_layers\n",
    "                )\n",
    "    decoder = Decoder(\n",
    "                    layer=TransformerLayer(\n",
    "                        d_model=d_model,\n",
    "                        self_attn=MultiHeadAttention(d_model=d_model, n_heads=n_heads, dropout_prob=dropout_prob),\n",
    "                        src_attn=MultiHeadAttention(d_model=d_model, n_heads=n_heads, dropout_prob=dropout_prob),\n",
    "                        feed_forward=FeedForward(d_model=d_model, d_ff=2048, dropout_prob=dropout_prob),\n",
    "                        dropout_prob=dropout_prob\n",
    "                    ), \n",
    "                    n_layers=n_layers\n",
    "                )\n",
    "    \n",
    "    src_embed = EmbeddingsWithPositionalEncoding(d_model=d_model, n_vocab=src_vocab_size, max_len=10)\n",
    "    tgt_embed = EmbeddingsWithPositionalEncoding(d_model=d_model, n_vocab=tgt_vocab_size, max_len=10)\n",
    "\n",
    "    generator = Generator(d_model=d_model, n_vocab=tgt_vocab_size)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        src_embed=src_embed,\n",
    "        tgt_embed=tgt_embed,\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ad07ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (query): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (key): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (value): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (output): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm_self_attn): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (query): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (key): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (value): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (output): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadAttention(\n",
       "          (query): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (key): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (value): PrepareForMultiHeadAttention(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (output): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm_self_attn): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_src_attn): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (src_embed): EmbeddingsWithPositionalEncoding(\n",
       "    (lut): Embedding(11, 512)\n",
       "  )\n",
       "  (tgt_embed): EmbeddingsWithPositionalEncoding(\n",
       "    (lut): Embedding(11, 512)\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (projection): Linear(in_features=512, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(src_vocab_size=11, tgt_vocab_size=11, n_layers=6, d_model=512, n_heads=8, dropout_prob=0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea47e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10]), torch.Size([2, 1, 10]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(2, 1, 10)\n",
    "src.shape, src_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeadcc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10, 512]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = model.encode(src, src_mask)\n",
    "ys = torch.ones(2, 1).type_as(src)\n",
    "memory.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819384a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7ef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    out = model.decode(\n",
    "        ys, memory, src_mask, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "    )\n",
    "    prob = model.generator(out[:, -1])\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.data[0]\n",
    "    ys = torch.cat(\n",
    "        [ys, torch.empty(2, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
